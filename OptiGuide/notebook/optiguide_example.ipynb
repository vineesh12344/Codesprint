{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a461c72d",
      "metadata": {
        "id": "a461c72d"
      },
      "source": [
        "# OptiGuide Example\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59a05fc7",
      "metadata": {
        "id": "59a05fc7"
      },
      "source": [
        "Here we give a simple example, as designed and illustrated in the [OptiGuide paper](https://arxiv.org/abs/2307.03875).\n",
        "While the original paper is designed specifically for supply chain optimization, the general framework can be easily adapted to other applications with coding capacity.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e92d200",
      "metadata": {
        "id": "5e92d200"
      },
      "source": [
        "## OptiGuide for Supply Chain Optimization: System Design Overview\n",
        "\n",
        "The original system design for OptiGuide, tailored for supply chain optimization, is presented below.\n",
        "\n",
        "The collaboration among three agents -- Coder, Safeguard, and Interpreter -- lies at the core of this system. They leverage a set of external tools and a large language model (LLM) to address users' questions related to supply chain applications. For a comprehensive understanding of the design and data flow, detailed information can be found in the original [paper](https://arxiv.org/abs/2307.03875).\n",
        "\n",
        "\n",
        "![optiguide system](https://www.beibinli.com/docs/optiguide/optiguide_system.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b7f90c8",
      "metadata": {
        "id": "8b7f90c8"
      },
      "source": [
        "## New Implementation\n",
        "\n",
        "\n",
        "\n",
        "![](new_design.png)\n",
        "\n",
        "Advantages of this multi-agent design with autogen:\n",
        "- Collaborative Problem Solving: The collaboration among the user proxy agent and the assistant agents fosters a cooperative problem-solving environment. The agents can share information and knowledge, allowing them to complement each other's abilities and collectively arrive at better solutions. On the other hand, the Safeguard acts as a virtual adversarial checker, which can perform another safety check pass on the generated code.\n",
        "\n",
        "- Modularity: The division of tasks into separate agents promotes modularity in the system. Each agent can be developed, tested, and maintained independently, simplifying the overall development process and facilitating code management.\n",
        "\n",
        "- Memory Management: The OptiGuide agent's role in maintaining memory related to user interactions is crucial. The memory retention allows the agents to have context about a user's prior questions, making the decision-making process more informed and context-aware.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "ReAgLnDma3oI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReAgLnDma3oI",
        "outputId": "c95a23e8-ddb9-4fd2-f218-c40a51cbcbb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: optiguide in c:\\users\\user\\desktop\\intern\\codesprint\\env\\lib\\site-packages (0.0.1)\n",
            "Requirement already satisfied: openai in c:\\users\\user\\desktop\\intern\\codesprint\\env\\lib\\site-packages (from optiguide) (0.28.1)\n",
            "Requirement already satisfied: diskcache in c:\\users\\user\\desktop\\intern\\codesprint\\env\\lib\\site-packages (from optiguide) (5.6.3)\n",
            "Requirement already satisfied: termcolor in c:\\users\\user\\desktop\\intern\\codesprint\\env\\lib\\site-packages (from optiguide) (2.3.0)\n",
            "Requirement already satisfied: flaml in c:\\users\\user\\desktop\\intern\\codesprint\\env\\lib\\site-packages (from optiguide) (2.1.0)\n",
            "Requirement already satisfied: autogen in c:\\users\\user\\desktop\\intern\\codesprint\\env\\lib\\site-packages (from optiguide) (1.0.16)\n",
            "Requirement already satisfied: eventlet in c:\\users\\user\\desktop\\intern\\codesprint\\env\\lib\\site-packages (from optiguide) (0.33.3)\n",
            "Requirement already satisfied: gurobipy in c:\\users\\user\\desktop\\intern\\codesprint\\env\\lib\\site-packages (from optiguide) (10.0.3)\n",
            "Requirement already satisfied: PyYAML in c:\\users\\user\\desktop\\intern\\codesprint\\env\\lib\\site-packages (from autogen->optiguide) (6.0.1)\n",
            "Requirement already satisfied: autopep8 in c:\\users\\user\\desktop\\intern\\codesprint\\env\\lib\\site-packages (from autogen->optiguide) (2.0.4)\n",
            "Requirement already satisfied: docopt in c:\\users\\user\\desktop\\intern\\codesprint\\env\\lib\\site-packages (from autogen->optiguide) (0.6.2)\n",
            "Requirement already satisfied: setuptools in c:\\users\\user\\desktop\\intern\\codesprint\\env\\lib\\site-packages (from autogen->optiguide) (65.5.0)\n",
            "Requirement already satisfied: twine in c:\\users\\user\\desktop\\intern\\codesprint\\env\\lib\\site-packages (from autogen->optiguide) (4.0.2)\n",
            "Requirement already satisfied: dnspython>=1.15.0 in c:\\users\\user\\desktop\\intern\\codesprint\\env\\lib\\site-packages (from eventlet->optiguide) (2.4.2)\n",
            "Requirement already satisfied: greenlet>=0.3 in c:\\users\\user\\desktop\\intern\\codesprint\\env\\lib\\site-packages (from eventlet->optiguide) (2.0.2)\n",
            "Requirement already satisfied: six>=1.10.0 in c:\\users\\user\\desktop\\intern\\codesprint\\env\\lib\\site-packages (from eventlet->optiguide) (1.16.0)\n",
            "Requirement already satisfied: NumPy>=1.17.0rc1 in c:\\users\\user\\desktop\\intern\\codesprint\\env\\lib\\site-packages (from flaml->optiguide) (1.26.0)\n",
            "Requirement already satisfied: requests>=2.20 in c:\\users\\user\\desktop\\intern\\codesprint\\env\\lib\\site-packages (from openai->optiguide) (2.31.0)\n",
            "Requirement already satisfied: tqdm in c:\\users\\user\\desktop\\intern\\codesprint\\env\\lib\\site-packages (from openai->optiguide) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in c:\\users\\user\\desktop\\intern\\codesprint\\env\\lib\\site-packages (from openai->optiguide) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\desktop\\intern\\codesprint\\env\\lib\\site-packages (from requests>=2.20->openai->optiguide) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\desktop\\intern\\codesprint\\env\\lib\\site-packages (from requests>=2.20->openai->optiguide) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\desktop\\intern\\codesprint\\env\\lib\\site-packages (from requests>=2.20->openai->optiguide) (2.0.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\desktop\\intern\\codesprint\\env\\lib\\site-packages (from requests>=2.20->openai->optiguide) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\desktop\\intern\\codesprint\\env\\lib\\site-packages (from aiohttp->openai->optiguide) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\user\\desktop\\intern\\codesprint\\env\\lib\\site-packages (from aiohttp->openai->optiguide) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\user\\desktop\\intern\\codesprint\\env\\lib\\site-packages (from aiohttp->openai->optiguide) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\user\\desktop\\intern\\codesprint\\env\\lib\\site-packages (from aiohttp->openai->optiguide) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\user\\desktop\\intern\\codesprint\\env\\lib\\site-packages (from aiohttp->openai->optiguide) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\user\\desktop\\intern\\codesprint\\env\\lib\\site-packages (from aiohttp->openai->optiguide) (1.3.1)\n",
            "Requirement already satisfied: pycodestyle>=2.10.0 in c:\\users\\user\\desktop\\intern\\codesprint\\env\\lib\\site-packages (from autopep8->autogen->optiguide) (2.11.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\user\\desktop\\intern\\codesprint\\env\\lib\\site-packages (from tqdm->openai->optiguide) (0.4.6)\n",
            "Requirement already satisfied: pkginfo>=1.8.1 in c:\\users\\user\\desktop\\intern\\codesprint\\env\\lib\\site-packages (from twine->autogen->optiguide) (1.9.6)\n",
            "Requirement already satisfied: readme-renderer>=35.0 in c:\\users\\user\\desktop\\intern\\codesprint\\env\\lib\\site-packages (from twine->autogen->optiguide) (42.0)\n",
            "Requirement already satisfied: requests-toolbelt!=0.9.0,>=0.8.0 in c:\\users\\user\\desktop\\intern\\codesprint\\env\\lib\\site-packages (from twine->autogen->optiguide) (1.0.0)\n",
            "Requirement already satisfied: importlib-metadata>=3.6 in c:\\users\\user\\desktop\\intern\\codesprint\\env\\lib\\site-packages (from twine->autogen->optiguide) (6.8.0)\n",
            "Requirement already satisfied: keyring>=15.1 in c:\\users\\user\\desktop\\intern\\codesprint\\env\\lib\\site-packages (from twine->autogen->optiguide) (24.2.0)\n",
            "Requirement already satisfied: rfc3986>=1.4.0 in c:\\users\\user\\desktop\\intern\\codesprint\\env\\lib\\site-packages (from twine->autogen->optiguide) (2.0.0)\n",
            "Requirement already satisfied: rich>=12.0.0 in c:\\users\\user\\desktop\\intern\\codesprint\\env\\lib\\site-packages (from twine->autogen->optiguide) (13.5.3)\n",
            "Requirement already satisfied: zipp>=0.5 in c:\\users\\user\\desktop\\intern\\codesprint\\env\\lib\\site-packages (from importlib-metadata>=3.6->twine->autogen->optiguide) (3.17.0)\n",
            "Requirement already satisfied: jaraco.classes in c:\\users\\user\\desktop\\intern\\codesprint\\env\\lib\\site-packages (from keyring>=15.1->twine->autogen->optiguide) (3.3.0)\n",
            "Requirement already satisfied: pywin32-ctypes>=0.2.0 in c:\\users\\user\\desktop\\intern\\codesprint\\env\\lib\\site-packages (from keyring>=15.1->twine->autogen->optiguide) (0.2.2)\n",
            "Requirement already satisfied: nh3>=0.2.14 in c:\\users\\user\\desktop\\intern\\codesprint\\env\\lib\\site-packages (from readme-renderer>=35.0->twine->autogen->optiguide) (0.2.14)\n",
            "Requirement already satisfied: docutils>=0.13.1 in c:\\users\\user\\desktop\\intern\\codesprint\\env\\lib\\site-packages (from readme-renderer>=35.0->twine->autogen->optiguide) (0.20.1)\n",
            "Requirement already satisfied: Pygments>=2.5.1 in c:\\users\\user\\desktop\\intern\\codesprint\\env\\lib\\site-packages (from readme-renderer>=35.0->twine->autogen->optiguide) (2.16.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\user\\desktop\\intern\\codesprint\\env\\lib\\site-packages (from rich>=12.0.0->twine->autogen->optiguide) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\user\\desktop\\intern\\codesprint\\env\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->twine->autogen->optiguide) (0.1.2)\n",
            "Requirement already satisfied: more-itertools in c:\\users\\user\\desktop\\intern\\codesprint\\env\\lib\\site-packages (from jaraco.classes->keyring>=15.1->twine->autogen->optiguide) (10.1.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3 -> 23.2.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# Install Required Packages\n",
        "%pip install optiguide"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "9a3b79c4",
      "metadata": {
        "id": "9a3b79c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# test Gurobi installation\n",
        "import gurobipy as gp\n",
        "from gurobipy import GRB\n",
        "from eventlet.timeout import Timeout\n",
        "\n",
        "# import auxillary packages\n",
        "import re\n",
        "import requests  # for loading the example source code\n",
        "import openai\n",
        "import os\n",
        "\n",
        "# import flaml and autogen\n",
        "from flaml import autogen\n",
        "from flaml.autogen.agentchat import Agent, UserProxyAgent\n",
        "from optiguide.optiguide import OptiGuideAgent\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "# Path to\n",
        "load_dotenv('.env')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "aedf19e7",
      "metadata": {
        "id": "aedf19e7"
      },
      "outputs": [],
      "source": [
        "autogen.oai.ChatCompletion.start_logging()\n",
        "\n",
        "config_list = autogen.config_list_from_json(\n",
        "    \"OAI_CONFIG_LIST\",\n",
        "    filter_dict={\n",
        "        \"model\": {\n",
        "            \"gpt-4\",\n",
        "            \"gpt4\",\n",
        "            \"gpt-4-32k\",\n",
        "            \"gpt-4-32k-0314\",\n",
        "            \"gpt-3.5-turbo\",\n",
        "            \"gpt-3.5-turbo-16k\",\n",
        "            \"gpt-3.5-turbo-0301\",\n",
        "            \"chatgpt-35-turbo-0301\",\n",
        "            \"gpt-35-turbo-v0301\",\n",
        "        }\n",
        "    }\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9e7e728",
      "metadata": {
        "id": "e9e7e728"
      },
      "source": [
        "Now, let's import the source code (loading from URL) and also some training examples (defined as string blow)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "ca962ac5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca962ac5",
        "outputId": "4a789991-8ba1-46f3-aad5-7fbaaaff7f02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "import pandas as pd\n",
            "import gurobipy as gp\n",
            "from gurobipy import GRB\n",
            "import time\n",
            "\n",
            "berthCapacities = dict({\"Berth1\" : 10000,\n",
            "               \"Berth2\" : 20000,\n",
            "               \"Berth3\" : 1000,\n",
            "               \"Berth4\" : 40000})\n",
            "\n",
            ".\n",
            ".\n",
            ".\n",
            "\n",
            "\n",
            "# Solve\n",
            "m.update()\n",
            "model.optimize()\n",
            "\n",
            "print(time.ctime())\n",
            "if m.status == GRB.OPTIMAL:\n",
            "    print(f'Optimal cost: {m.objVal}')\n",
            "else:\n",
            "    print(\"Not solved to optimality. Optimization status:\", m.status)\n"
          ]
        }
      ],
      "source": [
        "# Get the source code of our coffee example\n",
        "# code_url = \"https://raw.githubusercontent.com/microsoft/OptiGuide/main/benchmark/application/coffee.py\"\n",
        "code_url = \"https://raw.githubusercontent.com/vineesh12344/Codesprint/main/OptiGuide/benchmark/application/port.py\"\n",
        "response  = requests.get(code_url)\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    # Get the text content from the response\n",
        "    code = response.text\n",
        "else:\n",
        "    raise RuntimeError(\"Failed to retrieve the file.\")\n",
        "# code = open(code_url, \"r\").read() # for local files\n",
        "\n",
        "\n",
        "# show the first head and tail of the source code\n",
        "print(\"\\n\".join(code.split(\"\\n\")[:10]))\n",
        "print(\".\\n\" * 3)\n",
        "print(\"\\n\".join(code.split(\"\\n\")[-10:]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "d0570952",
      "metadata": {},
      "outputs": [],
      "source": [
        "# # In-context learning examples.\n",
        "# example_qa = \"\"\"\n",
        "# ----------\n",
        "# Question: Why is it not recommended to use just one supplier for roastery 2?\n",
        "# Answer Code:\n",
        "# ```python\n",
        "# z = m.addVars(suppliers, vtype=GRB.BINARY, name=\"z\")\n",
        "# m.addConstr(sum(z[s] for s in suppliers) <= 1, \"_\")\n",
        "# for s in suppliers:\n",
        "#     m.addConstr(x[s,'roastery2'] <= capacity_in_supplier[s] * z[s], \"_\")\n",
        "# ```\n",
        "\n",
        "# ----------\n",
        "# Question: What if there's a 13% jump in the demand for light coffee at cafe1?\n",
        "# Answer Code:\n",
        "# ```python\n",
        "# light_coffee_needed_for_cafe[\"cafe1\"] = light_coffee_needed_for_cafe[\"cafe1\"] * (1 + 13/100)\n",
        "# ```\n",
        "\n",
        "# \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "e31c4b36",
      "metadata": {
        "code_folding": [],
        "id": "e31c4b36"
      },
      "outputs": [],
      "source": [
        "# In-context learning examples.\n",
        "example_qa = \"\"\"\n",
        "----------\n",
        "Question: Why is it not recommended to only use one warehouse for berth 1?\n",
        "Answer Code:\n",
        "```python\n",
        "z = m.addVars(warehouses, vtype=GRB.BINARY, name=\"z\")\n",
        "m.addConstr(sum(z[w] for w in warehouses) <= 1, \"_\")\n",
        "for w in warehouses:\n",
        "    m.addConstr(shipping_costs['Berth1', w] <= warehouseCapacities[w] * z[w], \"_\")\n",
        "```\n",
        "\n",
        "----------\n",
        "Question: What if there's a 50% jump in the capacity of warehouse 1?\n",
        "Answer Code:\n",
        "```python\n",
        "warehouses[\"Warehouse1\"] = warehouses[\"Warehouse1\"] * (1 + 50/100)\n",
        "```\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a5a7d7e",
      "metadata": {
        "id": "5a5a7d7e"
      },
      "source": [
        "Now, let's create an OptiGuide agent and also a user.\n",
        "\n",
        "For the OptiGuide agent, we only allow \"debug_times\" to be 1, which means it can debug its answer once if it encountered errors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "af53727c",
      "metadata": {
        "id": "af53727c"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "agent = OptiGuideAgent(name=\"OptiGuide Coffee Example\",\n",
        "                  source_code=code,\n",
        "                   debug_times=1,\n",
        "                  example_qa=\"\",\n",
        "                llm_config={\n",
        "        \"request_timeout\": 600,\n",
        "        \"seed\": 42,\n",
        "        \"config_list\": config_list,\n",
        "    })\n",
        "\n",
        "user = UserProxyAgent(\"user\", max_consecutive_auto_reply=0,\n",
        "                         human_input_mode=\"NEVER\", code_execution_config=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd615e87",
      "metadata": {
        "id": "bd615e87"
      },
      "source": [
        "Now, let's create a user's question."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "24a76f67",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24a76f67",
        "outputId": "2399e32e-fe3f-429f-9c40-fcc75605741d",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33muser\u001b[0m (to OptiGuide Coffee Example):\n",
            "\n",
            "What if we prohibit shipping from supplier 1 to roastery 2?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33mOptiGuide Coffee Example\u001b[0m (to writer):\n",
            "\n",
            "\n",
            "Answer Code:\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33mwriter\u001b[0m (to OptiGuide Coffee Example):\n",
            "\n",
            "```python\n",
            "# OPTIGUIDE DATA CODE GOES HERE\n",
            "shipping_costs.pop((\"Berth1\", \"Warehouse2\"))\n",
            "routes = shipping_costs.keys()\n",
            "cost = list(shipping_costs.values())\n",
            "\n",
            "# OPTIGUIDE CONSTRAINT CODE GOES HERE\n",
            "```\n",
            "\n",
            "The code removes the route from Berth1 to Warehouse2 from your `shipping_costs` dictionary. Then we update the `routes` and `cost` variables to reflect the updated routes and shipping costs. This way, the model will not consider shipping from Berth1 to Warehouse2 when optimizing.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33mOptiGuide Coffee Example\u001b[0m (to safeguard):\n",
            "\n",
            "\n",
            "--- Code ---\n",
            "# OPTIGUIDE DATA CODE GOES HERE\n",
            "shipping_costs.pop((\"Berth1\", \"Warehouse2\"))\n",
            "routes = shipping_costs.keys()\n",
            "cost = list(shipping_costs.values())\n",
            "\n",
            "# OPTIGUIDE CONSTRAINT CODE GOES HERE\n",
            "\n",
            "--- One-Word Answer: SAFE or DANGER ---\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33msafeguard\u001b[0m (to OptiGuide Coffee Example):\n",
            "\n",
            "SAFE\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33mlist indices must be integers or slices, not tuple\u001b[0m\n",
            "\u001b[33mOptiGuide Coffee Example\u001b[0m (to writer):\n",
            "\n",
            "\n",
            "\n",
            "While running the code you suggested, I encountered the <class 'TypeError'>:\n",
            "--- ERROR MESSAGE ---\n",
            "list indices must be integers or slices, not tuple\n",
            "\n",
            "Please try to resolve this bug, and rewrite the code snippet.\n",
            "--- NEW CODE ---\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33mwriter\u001b[0m (to OptiGuide Coffee Example):\n",
            "\n",
            "Sorry for the confusion earlier, indeed the issue arises because we're trying to use tuples as indices for a list. Instead, just create a new cost dictionary after removing the key. Tuples can be used for keys in a dictionary structure, not lists.\n",
            "\n",
            "```python\n",
            "# OPTIGUIDE DATA CODE GOES HERE\n",
            "shipping_costs.pop((\"Berth1\", \"Warehouse2\"))\n",
            "routes = shipping_costs.keys()\n",
            "cost = dict((k, shipping_costs[k]) for k in routes)\n",
            "\n",
            "# OPTIGUIDE CONSTRAINT CODE GOES HERE\n",
            "```\n",
            "\n",
            "This code does exactly the same as before but instead of converting the cost to a list, we're making it a dictionary again. The TypeError should then be resolved.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33mOptiGuide Coffee Example\u001b[0m (to safeguard):\n",
            "\n",
            "\n",
            "--- Code ---\n",
            "# OPTIGUIDE DATA CODE GOES HERE\n",
            "shipping_costs.pop((\"Berth1\", \"Warehouse2\"))\n",
            "routes = shipping_costs.keys()\n",
            "cost = dict((k, shipping_costs[k]) for k in routes)\n",
            "\n",
            "# OPTIGUIDE CONSTRAINT CODE GOES HERE\n",
            "\n",
            "--- One-Word Answer: SAFE or DANGER ---\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33msafeguard\u001b[0m (to OptiGuide Coffee Example):\n",
            "\n",
            "SAFE\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Gurobi Optimizer version 10.0.3 build v10.0.3rc0 (win64)\n",
            "\n",
            "CPU model: AMD Ryzen 7 4800H with Radeon Graphics, instruction set [SSE2|AVX|AVX2]\n",
            "Thread count: 8 physical cores, 16 logical processors, using up to 16 threads\n",
            "\n",
            "Optimize a model with 8 rows, 15 columns and 0 nonzeros\n",
            "Model fingerprint: 0xbccaf91c\n",
            "Variable types: 0 continuous, 15 integer (0 binary)\n",
            "Coefficient statistics:\n",
            "  Matrix range     [0e+00, 0e+00]\n",
            "  Objective range  [5e+01, 6e+02]\n",
            "  Bounds range     [0e+00, 0e+00]\n",
            "  RHS range        [1e+03, 4e+04]\n",
            "Found heuristic solution: objective 35500.000000\n",
            "\n",
            "Explored 0 nodes (0 simplex iterations) in 0.01 seconds (0.00 work units)\n",
            "Thread count was 1 (of 16 available processors)\n",
            "\n",
            "Solution count 1: 35500 \n",
            "\n",
            "Optimal solution found (tolerance 1.00e-04)\n",
            "Best objective 3.550000000000e+04, best bound 3.550000000000e+04, gap 0.0000%\n",
            "Gurobi Optimizer version 10.0.3 build v10.0.3rc0 (win64)\n",
            "\n",
            "CPU model: AMD Ryzen 7 4800H with Radeon Graphics, instruction set [SSE2|AVX|AVX2]\n",
            "Thread count: 8 physical cores, 16 logical processors, using up to 16 threads\n",
            "\n",
            "Optimize a model with 8 rows, 15 columns and 0 nonzeros\n",
            "Model fingerprint: 0xbccaf91c\n",
            "Variable types: 0 continuous, 15 integer (0 binary)\n",
            "Coefficient statistics:\n",
            "  Matrix range     [0e+00, 0e+00]\n",
            "  Objective range  [5e+01, 6e+02]\n",
            "  Bounds range     [0e+00, 0e+00]\n",
            "  RHS range        [1e+03, 4e+04]\n",
            "\n",
            "\n",
            "\n",
            "Explored 0 nodes (0 simplex iterations) in 0.01 seconds (0.00 work units)\n",
            "Thread count was 1 (of 16 available processors)\n",
            "\n",
            "Solution count 1: 35500 \n",
            "\n",
            "Optimal solution found (tolerance 1.00e-04)\n",
            "Best objective 3.550000000000e+04, best bound 3.550000000000e+04, gap 0.0000%\n",
            "Sat Sep 30 21:08:07 2023\n",
            "Optimal cost: 35500.0\n",
            "\u001b[33mOptimization problem solved. The objective value is: 35500.0\u001b[0m\n",
            "\u001b[33mOptiGuide Coffee Example\u001b[0m (to writer):\n",
            "\n",
            "Here are the execution results: Optimization problem solved. The objective value is: 35500.0\n",
            "\n",
            "Can you organize these information to a human readable answer?\n",
            "Remember to compare the new results to the original results you obtained in the\n",
            "beginning.\n",
            "\n",
            "--- HUMAN READABLE ANSWER ---\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33mwriter\u001b[0m (to OptiGuide Coffee Example):\n",
            "\n",
            "Sure, I'd be glad to help!\n",
            "\n",
            "The initial model was unable to solve due to a 'dict_values' error. After prohibiting shipping from Berth1 to Warehouse2 and correcting the cost data structure error, the new model was successfully solved and the optimal objective value is 35500.0.\n",
            "\n",
            "This means that after stopping shipping from Berth1 to Warehouse2, the minimized total cost of shipping, factoring in both shipping costs and the remaining number of containers in the berths, is 35500 under given warehouse and berth capacities. Comparing this with the original model's results is not applicable as the original model did not successfully resolve given the error. \n",
            "\n",
            "It is important to note that the solution is subject to the weight factor (alpha) assigned to the cost in the objective function. Different values of alpha (other than 0.5 that was used in the model) may lead to different optimal solutions depending on whether more weight is given to reducing shipping costs or reducing the number of leftover containers.\n",
            "\n",
            "I hope this clarifies the answer. Do let me know if you have further questions!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33mOptiGuide Coffee Example\u001b[0m (to user):\n",
            "\n",
            "Sure, I'd be glad to help!\n",
            "\n",
            "The initial model was unable to solve due to a 'dict_values' error. After prohibiting shipping from Berth1 to Warehouse2 and correcting the cost data structure error, the new model was successfully solved and the optimal objective value is 35500.0.\n",
            "\n",
            "This means that after stopping shipping from Berth1 to Warehouse2, the minimized total cost of shipping, factoring in both shipping costs and the remaining number of containers in the berths, is 35500 under given warehouse and berth capacities. Comparing this with the original model's results is not applicable as the original model did not successfully resolve given the error. \n",
            "\n",
            "It is important to note that the solution is subject to the weight factor (alpha) assigned to the cost in the objective function. Different values of alpha (other than 0.5 that was used in the model) may lead to different optimal solutions depending on whether more weight is given to reducing shipping costs or reducing the number of leftover containers.\n",
            "\n",
            "I hope this clarifies the answer. Do let me know if you have further questions!\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "message = user.initiate_chat(agent, message=\"What if we prohibit shipping from supplier 1 to roastery 2?\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "cbdd1f28",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbdd1f28",
        "outputId": "c5e943cf-fce7-4484-8cd8-433d4fede8e5",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33muser\u001b[0m (to OptiGuide Coffee Example):\n",
            "\n",
            "What is the impact of supplier1 being able to supply only half the quantity at present?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33mOptiGuide Coffee Example\u001b[0m (to writer):\n",
            "\n",
            "\n",
            "Answer Code:\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33mwriter\u001b[0m (to OptiGuide Coffee Example):\n",
            "\n",
            "```python\n",
            "# updating the berth capacity of the Berth1 to be half\n",
            "berthCapacities[\"Berth1\"] = berthCapacities[\"Berth1\"] / 2\n",
            "\n",
            "# updating the constraints in the model\n",
            "for berth in berthCapacities.keys():\n",
            "    berth_constrs[berth].RHS = berthCapacities[berth]\n",
            "\n",
            "# optimizing the model after updating constraints\n",
            "model.optimize()\n",
            "```\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33mOptiGuide Coffee Example\u001b[0m (to safeguard):\n",
            "\n",
            "\n",
            "--- Code ---\n",
            "# updating the berth capacity of the Berth1 to be half\n",
            "berthCapacities[\"Berth1\"] = berthCapacities[\"Berth1\"] / 2\n",
            "\n",
            "# updating the constraints in the model\n",
            "for berth in berthCapacities.keys():\n",
            "    berth_constrs[berth].RHS = berthCapacities[berth]\n",
            "\n",
            "# optimizing the model after updating constraints\n",
            "model.optimize()\n",
            "\n",
            "--- One-Word Answer: SAFE or DANGER ---\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33msafeguard\u001b[0m (to OptiGuide Coffee Example):\n",
            "\n",
            "SAFE\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33mname 'berth_constrs' is not defined\u001b[0m\n",
            "\u001b[33mOptiGuide Coffee Example\u001b[0m (to writer):\n",
            "\n",
            "\n",
            "\n",
            "While running the code you suggested, I encountered the <class 'NameError'>:\n",
            "--- ERROR MESSAGE ---\n",
            "name 'berth_constrs' is not defined\n",
            "\n",
            "Please try to resolve this bug, and rewrite the code snippet.\n",
            "--- NEW CODE ---\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33mwriter\u001b[0m (to OptiGuide Coffee Example):\n",
            "\n",
            "Apologies for the confusion. It seems in your original code, `berth_constrs` is never defined. However, while adding constraints to the model, the indices can be stored. Let's modify the code where constraints are added to the model:\n",
            "\n",
            "```python\n",
            "# Add and store berth capacity constraints\n",
            "berth_constrs = {berth: model.addConstr(gp.quicksum(trucks.select('*', berth)) <= berthCapacities[berth]) for berth in berthCapacities.keys()}\n",
            "```\n",
            "\n",
            "Then, you can modify `berthCapacities[\"Berth1\"]` and update the constraints like before:\n",
            "\n",
            "```python\n",
            "# updating the berth capacity of the Berth1 to be half\n",
            "berthCapacities[\"Berth1\"] = berthCapacities[\"Berth1\"] / 2\n",
            "\n",
            "# updating the constraints in the model\n",
            "berth_constrs[\"Berth1\"].RHS = berthCapacities[\"Berth1\"]\n",
            "\n",
            "# optimizing the model after updating constraints\n",
            "model.optimize()\n",
            "```\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33mOptiGuide Coffee Example\u001b[0m (to safeguard):\n",
            "\n",
            "\n",
            "--- Code ---\n",
            "# Add and store berth capacity constraints\n",
            "berth_constrs = {berth: model.addConstr(gp.quicksum(trucks.select('*', berth)) <= berthCapacities[berth]) for berth in berthCapacities.keys()}\n",
            "\n",
            "--- One-Word Answer: SAFE or DANGER ---\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33msafeguard\u001b[0m (to OptiGuide Coffee Example):\n",
            "\n",
            "SAFE\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33m'dict_values' object is not subscriptable\u001b[0m\n",
            "\u001b[33mOptiGuide Coffee Example\u001b[0m (to user):\n",
            "\n",
            "Sorry. I cannot answer your question.\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "user.initiate_chat(agent, message=\"What is the impact of supplier1 being able to supply only half the quantity at present?\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
